{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phrase retrieval\n",
    "\n",
    "### Biword retrieval\n",
    "\n",
    "### Positional indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open file and create vocab\n",
    "vocab = []\n",
    "docs = []\n",
    "filename = \"21-most-cited-machine-learning-papers_titles.txt\"\n",
    "\n",
    "with open(filename, encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        # Word tokenization \n",
    "\n",
    "        title = line.split(\"|\")[0].lower()\n",
    "        docs.append(title)\n",
    "        for word in title.split():\n",
    "            if word not in vocab:\n",
    "                vocab.append(word)\n",
    "\n",
    "\n",
    "print(len(vocab), \"\\n\", vocab,\"\\n\", len(docs), \"\\n\", docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: deep learning\n",
      "Matching Document IDs: [6]\n"
     ]
    }
   ],
   "source": [
    "# biword retrieval\n",
    "import re\n",
    "\n",
    "def preprocess_text(text):\n",
    "\n",
    "    # Lowercase and remove punctuation\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    return text.split()\n",
    "\n",
    "def build_biword_index(documents):\n",
    "    biword_index = {}\n",
    "\n",
    "    for doc_id, document in enumerate(documents):\n",
    "        words = preprocess_text(document)\n",
    "        # Create biwords from consecutive words\n",
    "        for i in range(len(words) - 1):\n",
    "            biword = (words[i], words[i + 1])\n",
    "            if biword in biword_index.keys():\n",
    "                biword_index[biword] += [doc_id]\n",
    "            else:\n",
    "                biword_index[biword] = [doc_id]\n",
    "    \n",
    "    return biword_index\n",
    "\n",
    "def search_biword_index(biword_index, query):\n",
    "    words = preprocess_text(query)\n",
    "    if len(words) < 2:\n",
    "        return set()  # No biwords in query\n",
    "    query_biwords = [(words[i], words[i + 1]) for i in range(len(words) - 1)]\n",
    "    \n",
    "    # Find the intersection of documents containing all query biwords\n",
    "    result_docs = None\n",
    "    for biword in query_biwords:\n",
    "        if biword in biword_index:\n",
    "            if result_docs is None:\n",
    "                result_docs = biword_index[biword]\n",
    "            else:\n",
    "                result_docs = result_docs.intersection(biword_index[biword])\n",
    "        else:\n",
    "            return set()  # No match for a biword\n",
    "\n",
    "    return result_docs if result_docs else set()\n",
    "\n",
    "\n",
    "# Build the biword index\n",
    "biword_index = build_biword_index(docs)\n",
    "\n",
    "# Perform a search\n",
    "query = \"deep learning\"\n",
    "result = search_biword_index(biword_index, query)\n",
    "\n",
    "print(\"Query:\", query)\n",
    "print(\"Matching Document IDs:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: deep learning\n",
      "Matching Document IDs: {6}\n"
     ]
    }
   ],
   "source": [
    "# positional indexes\n",
    "from collections import defaultdict\n",
    "\n",
    "def preprocess_text(text):\n",
    "    import re\n",
    "    # Lowercase and remove punctuation\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    return text.split()\n",
    "\n",
    "def build_positional_index(documents):\n",
    "\n",
    "    positional_index = defaultdict(list)\n",
    "\n",
    "    for doc_id, document in enumerate(documents):\n",
    "        words = preprocess_text(document)\n",
    "        for pos, word in enumerate(words):\n",
    "            # Append the position to the term's entry\n",
    "            if positional_index[word] and positional_index[word][-1][0] == doc_id:\n",
    "                positional_index[word][-1][1].append(pos)\n",
    "            else:\n",
    "                positional_index[word].append((doc_id, [pos]))\n",
    "\n",
    "    return positional_index\n",
    "\n",
    "def search_phrase(positional_index, query, documents):\n",
    "\n",
    "    words = preprocess_text(query)\n",
    "    if not words:\n",
    "        return set()\n",
    "\n",
    "    # Find the list of (doc_id, positions) for each word in the query\n",
    "    word_positions = [positional_index.get(word, []) for word in words]\n",
    "    if not all(word_positions):\n",
    "        return set()\n",
    "\n",
    "    # Find documents containing all words with correct relative positions\n",
    "    result_docs = set(doc_id for doc_id, _ in word_positions[0])\n",
    "    for i in range(1, len(words)):\n",
    "        next_result_docs = set()\n",
    "        for doc_id, positions in word_positions[i]:\n",
    "            for prev_doc_id, prev_positions in word_positions[i - 1]:\n",
    "                if doc_id == prev_doc_id:\n",
    "                    if any(pos + 1 in positions for pos in prev_positions):\n",
    "                        next_result_docs.add(doc_id)\n",
    "                        break\n",
    "        result_docs &= next_result_docs\n",
    "        if not result_docs:\n",
    "            return set()\n",
    "\n",
    "    return result_docs\n",
    "\n",
    "\n",
    "# Build the biword index\n",
    "biword_index = build_positional_index(docs)\n",
    "\n",
    "# Perform a search\n",
    "query = \"deep learning\"\n",
    "result = search_phrase(biword_index, query, docs)\n",
    "\n",
    "print(\"Query:\", query)\n",
    "print(\"Matching Document IDs:\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Homework 1:\n",
    "# Implement the skip pointer\n",
    "\n",
    "# Homework 2:\n",
    "# what is the order of skip pointers in both the best and worst cases.\n",
    "\n",
    "# What are the advantages and disadvantages of positional and biword retrieval. Compare them in a table."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
